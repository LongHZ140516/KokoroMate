"use client"

import React from "react"
import {
  PromptInput,
  PromptInputAction,
  PromptInputActions,
  PromptInputTextarea,
} from "@/components/ui/prompt-input"
import { Button } from "@/components/ui/button"
import { ArrowUp, Square, Mic, MicOff } from "lucide-react"
import { useState, useRef, useEffect } from "react"
import { sendTextMessage, sendAudioMessage } from "../data/api-service"
import { AudioRecorder } from "../data/audio-recorder"
import type { ChatMessage } from "../data/chat-message"

interface MessageInputProps {
  onMessageSending?: (userMessage: ChatMessage) => void; // æ–°å¢ï¼šå‘é€å‰ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
  onMessageSent?: (userMessage: ChatMessage, roleMessage: ChatMessage, motionName?: string, audioPath?: string) => void;
  disabled?: boolean;
}

export function MessageInput({ onMessageSending, onMessageSent, disabled = false }: MessageInputProps) {
  const [input, setInput] = useState("")
  const [isLoading, setIsLoading] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [error, setError] = useState<string | null>(null)
  
  const audioRecorderRef = useRef<AudioRecorder | null>(null)

  // åˆå§‹åŒ–éŸ³é¢‘å½•åˆ¶å™¨
  useEffect(() => {
    audioRecorderRef.current = new AudioRecorder()
    
    return () => {
      audioRecorderRef.current?.cleanup()
    }
  }, [])

  // å‘é€æ–‡æœ¬æ¶ˆæ¯
  const handleTextSubmit = async () => {
    if (!input.trim() || isLoading || disabled) return

    const userText = input.trim()
    setInput("")
    setIsLoading(true)
    setError(null)

    // åˆ›å»ºç”¨æˆ·æ¶ˆæ¯å¹¶ç«‹å³æ˜¾ç¤º
    const userMessage: ChatMessage = {
      sender: "You",
      message: userText,
      timestamp: new Date(),
      files: []
    }

    // ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    if (onMessageSending) {
      onMessageSending(userMessage);
    }

    try {
      // å‘é€åˆ°åç«¯
      const response = await sendTextMessage(userText)
      
      // åˆ›å»ºè§’è‰²å›å¤æ¶ˆæ¯
      const roleMessage: ChatMessage = {
        sender: "Role",
        message: response.text,
        timestamp: new Date(),
        files: []
      }

      // å†å²è®°å½•ä¿å­˜å°†åœ¨ä¸»é¡µé¢ä¸­å¤„ç†ï¼Œé¿å…é‡å¤ä¿å­˜
      // addMessageToHistory(updatedUserMessage)
      // addMessageToHistory(roleMessage)

      // é€šçŸ¥çˆ¶ç»„ä»¶ï¼ˆä¼ é€’è§’è‰²å›å¤å’ŒåŠ¨ç”»ä¿¡æ¯ï¼‰
      if (onMessageSent) {
        onMessageSent(userMessage, roleMessage, response.motion, response.audio_path);
      }

      // console.log('Text message sent successfully:', { 
      //   userText, 
      //   response: response.text, 
      //   motion: response.motion 
      // })
    } catch (error) {
      console.error('Error sending text message:', error)
      setError('Failed to send message. Please try again.')
    } finally {
      setIsLoading(false)
    }
  }

  // å¼€å§‹å½•éŸ³
  const handleStartRecording = async () => {
    if (isLoading || disabled) return

    try {
      setError(null)
      await audioRecorderRef.current?.startRecording()
      setIsRecording(true)
      // console.log('Recording started')
    } catch (error) {
      console.error('Error starting recording:', error)
      setError('Failed to start recording. Please check microphone permissions.')
    }
  }

  // åœæ­¢å½•éŸ³å¹¶å‘é€
  const handleStopRecording = async () => {
    if (!audioRecorderRef.current || !isRecording) return

    setIsRecording(false)
    setIsLoading(true)
    setError(null)

    // åˆ›å»ºç”¨æˆ·è¯­éŸ³æ¶ˆæ¯å¹¶ç«‹å³æ˜¾ç¤ºï¼ˆä½¿ç”¨è¯­éŸ³å›¾æ ‡ï¼‰
    const userMessage: ChatMessage = {
      sender: "You",
      message: "ğŸ¤ Audio Message", // ä¸´æ—¶æ˜¾ç¤ºéŸ³é¢‘æ¶ˆæ¯
      timestamp: new Date(),
      files: []
    }

    // ç«‹å³æ˜¾ç¤ºè¯­éŸ³æ¶ˆæ¯
    if (onMessageSending) {
      onMessageSending(userMessage);
    }

    try {
      // åœæ­¢å½•åˆ¶
      // console.log('ğŸ¤ Stopping recording...');
      const audioBlob = await audioRecorderRef.current.stopRecording()
      // console.log('ğŸ¤ Recording stopped, blob size:', audioBlob.size, 'type:', audioBlob.type);

      // å‘é€åˆ°åç«¯
      // console.log('ğŸ¤ Sending audio to backend...');
      const response = await sendAudioMessage(audioBlob)
      // console.log('ğŸ¤ Backend response:', response);
      
      // æ›´æ–°ç”¨æˆ·æ¶ˆæ¯ä¸ºéŸ³é¢‘å›¾æ ‡+ASRè¯†åˆ«çš„æ–‡æœ¬
      const updatedUserMessage: ChatMessage = {
        sender: "You",
        message: response.asr_text ? `ğŸµ ${response.asr_text}` : "ğŸµ Voice Message",
        timestamp: new Date(),
        files: []
      }

      // åˆ›å»ºè§’è‰²å›å¤æ¶ˆæ¯
      const roleMessage: ChatMessage = {
        sender: "Role",
        message: response.text,
        timestamp: new Date(),
        files: []
      }

      // ä¿å­˜åˆ°å†å²è®°å½•
      // addMessageToHistory(updatedUserMessage)
      // addMessageToHistory(roleMessage)

      // é€šçŸ¥çˆ¶ç»„ä»¶ï¼ˆä¼ é€’æ›´æ–°åçš„ç”¨æˆ·æ¶ˆæ¯ã€è§’è‰²å›å¤å’ŒåŠ¨ç”»ä¿¡æ¯ï¼‰
      if (onMessageSent) {
        onMessageSent(updatedUserMessage, roleMessage, response.motion, response.audio_path);
      }

      // console.log('Audio message sent successfully:', { 
      //   asr: response.asr_text, 
      //   response: response.text,
      //   motion: response.motion 
      // })
    } catch (error) {
      console.error('Error sending audio message:', error)
      setError('Failed to process audio message. Please try again.')
    } finally {
      setIsLoading(false)
    }
  }

  // å¤„ç†é”®ç›˜äº‹ä»¶
  const handleKeyDown = (event: React.KeyboardEvent) => {
    if (event.key === 'Enter' && !event.shiftKey) {
      event.preventDefault()
      handleTextSubmit()
    }
  }

  return (
    <div className="space-y-2">
      {/* é”™è¯¯æç¤º */}
      {error && (
        <div className="text-sm text-destructive bg-destructive/10 border border-destructive/20 rounded-lg p-2 w-[40vw]">
          {error}
        </div>
      )}

      <div className="flex items-center gap-3 w-[40vw]">
        {/* è¯­éŸ³å½•åˆ¶æŒ‰é’® - åœ¨è¾“å…¥æ¡†å·¦ä¾§ */}
        <Button
          variant="outline"
          size="icon"
          className={`w-[2vw] h-[2vw] rounded-full shrink-0 transition-all duration-200 ${
            isRecording 
              ? 'bg-orange-500 hover:bg-orange-600 border-orange-500 text-white shadow-lg' 
              : 'bg-background/15 backdrop-blur-sm shadow-2xl border-1 hover:bg-background/50'
          }`}
          onClick={isRecording ? handleStopRecording : handleStartRecording}
          disabled={disabled || isLoading}
        >
          {isRecording ? (
            <MicOff className="size-5" />
          ) : (
            <Mic className="size-5" />
          )}
        </Button>

        {/* æ–‡æœ¬è¾“å…¥æ¡† */}
        <PromptInput
          value={input}
          onValueChange={setInput}
          isLoading={isLoading}
          onSubmit={handleTextSubmit}
          className="flex-1 bg-background/15 backdrop-blur-sm shadow-2xl border-1 rounded-2xl"
        >
          <PromptInputTextarea 
            placeholder={isRecording ? "Recording..." : "Ask me anything..."} 
            onKeyDown={handleKeyDown}
            disabled={disabled || isLoading || isRecording}
          />
          
          <PromptInputActions className="justify-end pt-2">
            {/* å‘é€æŒ‰é’® */}
            <PromptInputAction
              tooltip={isLoading ? "Processing..." : "Send message"}
            >
              <Button
                variant="default"
                size="icon"
                className="h-8 w-8 rounded-full"
                onClick={handleTextSubmit}
                disabled={disabled || isLoading || isRecording || !input.trim()}
              >
                {isLoading ? (
                  <Square className="size-4 fill-current" />
                ) : (
                  <ArrowUp className="size-4" />
                )}
              </Button>
            </PromptInputAction>
          </PromptInputActions>
        </PromptInput>
      </div>
    </div>
  )
}
